{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('voice.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000      1  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632      1  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512      1  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119      1  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274      1  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929      0  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897      0  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759      0  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002      0  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000      0  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Преобразование категориальных меток в числовые\n",
    "data['label'] = le.fit_transform(data['label'])\n",
    "\n",
    "# Разделение данных на признаки (X) и метки (y)\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Разделение данных на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values  # Преобразование DataFrame в numpy array\n",
    "X_test = X_test.values\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.tree_ = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs) for inputs in X])\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while not node.is_leaf:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left_child\n",
    "            else:\n",
    "                node = node.right_child\n",
    "        return node.value\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if (n_labels == 1) or (n_samples < self.min_samples_split) or \\\n",
    "           (self.max_depth is not None and depth >= self.max_depth):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return DecisionTreeNode(value=leaf_value)\n",
    "\n",
    "        feature_indices = np.arange(n_features)\n",
    "        feature_index, threshold = self._best_split(X, y, feature_indices)\n",
    "\n",
    "        if feature_index is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return DecisionTreeNode(value=leaf_value)\n",
    "\n",
    "        left_indices = X[:, feature_index] < threshold\n",
    "        right_indices = ~left_indices\n",
    "        left_child = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_child = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "        return DecisionTreeNode(feature_index=feature_index, threshold=threshold,\n",
    "                                left_child=left_child, right_child=right_child)\n",
    "\n",
    "    def _best_split(self, X, y, feature_indices):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        for idx in feature_indices:\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature_index=None, threshold=None,\n",
    "                 left_child=None, right_child=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.value = value\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    indent = \"  \" * depth\n",
    "    if node.is_leaf:\n",
    "        print(indent + f\"Class: {node.value}\")\n",
    "    else:\n",
    "        print(indent + f\"Feature {node.feature_index} <= {node.threshold}\")\n",
    "        print_tree(node.left_child, depth + 1)\n",
    "        print_tree(node.right_child, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(X_train, y_train, X_test, y_test, n_estimators, learning_rate, max_depth):\n",
    "    # Инициализируем список для хранения базовых моделей\n",
    "    base_models = []\n",
    "    \n",
    "    # Инициализируем список для хранения весов базовых моделей\n",
    "    model_weights = []\n",
    "    \n",
    "    # Инициализируем предсказания для обучающей и тестовой выборок\n",
    "    train_predictions = np.zeros(len(X_train))\n",
    "    test_predictions = np.zeros(len(X_test))\n",
    "    \n",
    "    for i in range(n_estimators):\n",
    "        # Создаем и обучаем базовую модель (DecisionTree)\n",
    "        base_model = DecisionTree(max_depth=max_depth)\n",
    "        base_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Вычисляем ошибку (разницу между реальными метками и предсказаниями)\n",
    "        errors = y_train - train_predictions\n",
    "        \n",
    "        # Вычисляем вес базовой модели как learning_rate умноженное на ошибку\n",
    "        model_weight = learning_rate * errors.mean()\n",
    "        \n",
    "        # Обновляем предсказания для обучающей и тестовой выборок\n",
    "        train_predictions += model_weight * base_model.predict(X_train)\n",
    "        test_predictions += model_weight * base_model.predict(X_test)\n",
    "        \n",
    "        # Добавляем базовую модель и ее вес в списки\n",
    "        base_models.append(base_model)\n",
    "        model_weights.append(model_weight)\n",
    "    \n",
    "    # Вычисляем финальные предсказания модели\n",
    "    final_predictions = np.sign(test_predictions)\n",
    "    \n",
    "    return base_models, model_weights, final_predictions\n",
    "\n",
    "n_estimators = 10\n",
    "learning_rate = 0.1\n",
    "max_depth = 2\n",
    "\n",
    "base_models, model_weights, final_predictions = gradient_boosting(X_train, y_train, X_test, y_test, n_estimators, learning_rate, max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9400630914826499\n",
      "Точность (Precision): 0.9838187702265372\n",
      "Полнота (Recall): 0.9020771513353115\n",
      "F1-мера: 0.9411764705882352\n",
      "\n",
      "model_weights:\n",
      " 0.04921073401736385\n",
      "0.046901674714023456\n",
      "0.04470096077420602\n",
      "0.04260350843164363\n",
      "0.04060447245985104\n",
      "0.03869923497939473\n",
      "0.03688339479034578\n",
      "0.03515275720527391\n",
      "0.033503324359296385\n",
      "0.031931285974797434\n",
      "\n",
      "\n",
      "Structure of Decision Tree 1:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 2:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 3:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 4:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 5:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 6:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 7:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 8:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 9:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n",
      "\n",
      "\n",
      "Structure of Decision Tree 10:\n",
      "Feature 12 <= 0.1394832907893745\n",
      "  Feature 5 <= 0.07127338175740824\n",
      "    Class: 0\n",
      "    Class: 1\n",
      "  Feature 12 <= 0.1476299329104555\n",
      "    Class: 0\n",
      "    Class: 0\n"
     ]
    }
   ],
   "source": [
    "# вычисляем точность (accuracy) модели\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "# вычисляем точность (precision)\n",
    "precision = precision_score(y_test, final_predictions)\n",
    "# вычисляем полноту (recall)\n",
    "recall = recall_score(y_test, final_predictions)\n",
    "# вычисляем F1-меру\n",
    "f1 = f1_score(y_test, final_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Точность (Precision):\", precision)\n",
    "print(\"Полнота (Recall):\", recall)\n",
    "print(\"F1-мера:\", f1)\n",
    "\n",
    "print(\"\\nmodel_weights:\\n\", model_weights)\n",
    "\n",
    "for i,m in enumerate(base_models):\n",
    "    print(\"\\n\")\n",
    "    print(f\"Structure of Decision Tree {i + 1}:\")\n",
    "    print_tree(m.tree_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

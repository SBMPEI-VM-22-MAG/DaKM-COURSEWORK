{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment # 1\n",
      "n_e =  20\n",
      "l_r 0.1\n",
      "m_d 5\n",
      "Tree= 1\n",
      "Tree= 2\n",
      "Tree= 3\n",
      "Tree= 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39ml_r\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mm_d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m accuracy, precision, recall, f1 \u001b[39m=\u001b[39m evaluate(X \u001b[39m=\u001b[39;49m X, y \u001b[39m=\u001b[39;49m y)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m accuracy_results\u001b[39m.\u001b[39mappend(accuracy)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m precision_results\u001b[39m.\u001b[39mappend(precision)\n",
      "\u001b[1;32m/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m clf \u001b[39m=\u001b[39m CustomGBDT(n_estimators\u001b[39m=\u001b[39mn_e, learning_rate\u001b[39m=\u001b[39ml_r, max_depth\u001b[39m=\u001b[39mm_d)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/kinwend17/myDocs/DaKM/DaKM-COURSEWORK/src/MyGradientBoostingDT_Synthetic.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# оценка модели\u001b[39;00m\n",
      "File \u001b[0;32m~/myDocs/DaKM/DaKM-COURSEWORK/src/CustomGBDT.py:26\u001b[0m, in \u001b[0;36mCustomGBDT.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m# обучаем дерево на градиенте\u001b[39;00m\n\u001b[1;32m     25\u001b[0m tree \u001b[39m=\u001b[39m CustomDecisionTree(max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_depth)\n\u001b[0;32m---> 26\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X, gradient)  \u001b[39m# градиент вместо меток\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m# вычисляем прогнозы базовой модели\u001b[39;00m\n\u001b[1;32m     29\u001b[0m tree_predictions \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m~/myDocs/DaKM/DaKM-COURSEWORK/src/CustomDecisionTree.py:10\u001b[0m, in \u001b[0;36mCustomDecisionTree.fit\u001b[0;34m(self, features, labels, current_depth)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, features, labels):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_dt(features, labels)\n",
      "File \u001b[0;32m~/myDocs/DaKM/DaKM-COURSEWORK/src/CustomDecisionTree.py:73\u001b[0m, in \u001b[0;36mCustomDecisionTree._build_dt\u001b[0;34m(self, features, labels, current_depth)\u001b[0m\n\u001b[1;32m     70\u001b[0m n, n_left, n_right \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(labels), \u001b[39mlen\u001b[39m(left_indices), \u001b[39mlen\u001b[39m(right_indices)\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m (n_left \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m n_right \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m---> 73\u001b[0m     child_entropy \u001b[39m=\u001b[39m (n_left \u001b[39m/\u001b[39m n) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_entropy(labels[left_indices]) \u001b[39m+\u001b[39m (n_right \u001b[39m/\u001b[39m n) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_entropy(labels[right_indices])\n\u001b[1;32m     74\u001b[0m     score \u001b[39m=\u001b[39m parent_entropy \u001b[39m-\u001b[39m child_entropy\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m (score \u001b[39m>\u001b[39m split_score):\n",
      "File \u001b[0;32m~/myDocs/DaKM/DaKM-COURSEWORK/src/CustomDecisionTree.py:37\u001b[0m, in \u001b[0;36mCustomDecisionTree._entropy\u001b[0;34m(self, labels)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m count \u001b[39min\u001b[39;00m unique_counts\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m     36\u001b[0m     p \u001b[39m=\u001b[39m count \u001b[39m/\u001b[39m n\n\u001b[0;32m---> 37\u001b[0m     entropy \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m p \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog2(p)\n\u001b[1;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m entropy\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from CustomGBDT import CustomGBDT\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.datasets import make_classification  \n",
    "\n",
    "# генерация синтетических данных\n",
    "X, y = make_classification(n_samples=3000, n_features=20)\n",
    "y = y.astype(int)  # Преобразуйте метки в целые числа\n",
    "\n",
    "num_experiments = 5\n",
    "# n_e = [16, 17, 18, 19, 20]\n",
    "# l_r = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "# m_d = [3, 3, 3, 4, 5]\n",
    "\n",
    "# хранения результатов метрик для подсчёта среднего\n",
    "accuracy_results = []\n",
    "precision_results = []\n",
    "recall_results = []\n",
    "f1_results = []\n",
    "\n",
    "def evaluate(X, y, n_e=20, l_r=0.1, m_d=5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    clf = CustomGBDT(n_estimators=n_e, learning_rate=l_r, max_depth=m_d)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # оценка модели\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "idx = 0\n",
    "for i in range(num_experiments):\n",
    "    idx += 1\n",
    "    print(\"experiment #\", idx)\n",
    "    print(\"n_e = \", 20)\n",
    "    print(\"l_r\", 0.1)\n",
    "    print(\"m_d\", 5)\n",
    "    accuracy, precision, recall, f1 = evaluate(X = X, y = y)\n",
    "\n",
    "    accuracy_results.append(accuracy)\n",
    "    precision_results.append(precision)\n",
    "    recall_results.append(recall)\n",
    "    f1_results.append(f1)\n",
    "    print(\"###############################\\n\")\n",
    "\n",
    "# вычисление средних значений\n",
    "average_accuracy = sum(accuracy_results) / num_experiments\n",
    "average_precision = sum(precision_results) / num_experiments\n",
    "average_recall = sum(recall_results) / num_experiments\n",
    "average_f1 = sum(f1_results) / num_experiments\n",
    "\n",
    "# средние значения\n",
    "print(f'Средняя точность (Accuracy) по {num_experiments} экспериментам: {average_accuracy:.2f}')\n",
    "print(f'Средняя точность (Precision) по {num_experiments} экспериментам: {average_precision:.2f}')\n",
    "print(f'Средняя полнота (Recall) по {num_experiments} экспериментам: {average_recall:.2f}')\n",
    "print(f'Средняя F1-мера по {num_experiments} экспериментам: {average_f1:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
